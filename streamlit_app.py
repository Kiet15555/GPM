# Tá»”NG Há»¢P Tá»ª STEP 1 Äáº¾N 20 (PHIÃŠN Báº¢N Äáº¦Y Äá»¦ - ÄÃƒ FIX Lá»–I WEBGL & Cá» Äá»ŠNH RANDOM SEED)
import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime
import warnings
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import os
import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
from plotly.subplots import make_subplots 
from scipy.optimize import minimize
import quantstats as qs

# --- Cáº¥u hÃ¬nh Trang & CÃ¡c thiáº¿t láº­p ban Ä‘áº§u ---
warnings.filterwarnings('ignore')
st.set_page_config(layout="wide", page_title="Tá»‘i Æ°u Danh má»¥c VN30 Pro")
st.title("ğŸ“ˆ á»¨ng dá»¥ng PhÃ¢n tÃ­ch & Tá»‘i Æ°u hÃ³a Danh má»¥c VN30 (Báº£n Full)")

# Set theme máº·c Ä‘á»‹nh cho Plotly
pio.templates.default = "plotly_dark"


# === CÃC HÃ€M Äá»ŠNH NGHÄ¨A (Gá»˜P Tá»ª CÃC FILE) ===

# --- Tá»« Step2.py (Ã” 2) ---
def get_price_history_api(symbol: str, start_date: datetime, end_date: datetime):
    all_data = []
    page = 1
    total_pages = 1
    while page <= total_pages:
        url = "https://cafef.vn/du-lieu/Ajax/PageNew/DataHistory/PriceHistory.ashx"
        params = {"Symbol": symbol, "StartDate": start_date.strftime("%Y-%m-%d"),
                  "EndDate": end_date.strftime("%Y-%m-%d"), "PageIndex": page}
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            if not data.get("Success", False): break
            records = data["Data"]["Data"]
            if not records: break
            if page == 1:
                total_count = data["Data"]["TotalCount"]
                total_pages = -(-total_count // len(records))
            all_data.extend(records)
            page += 1
        except Exception as e:
            print(f"Lá»—i khi gá»i API CafeF cho {symbol}: {e}")
            return None
    if not all_data: return None
    df = pd.DataFrame(all_data)
    df['Ticker'] = symbol.upper()
    numeric_columns = ['GiaDieuChinh', 'GiaDongCua', 'KhoiLuongKhopLenh', 
                      'GiaTriKhopLenh', 'GiaMoCua', 'GiaCaoNhat', 'GiaThapNhat']
    for col in numeric_columns: df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.sort_values('Ngay', ascending=True).reset_index(drop=True)
    df['GiaDongCua'].replace(0, np.nan, inplace=True); df['GiaDongCua'] = df['GiaDongCua'].ffill().bfill()
    df.loc[df['GiaDongCua'] == 0, 'GiaDieuChinh'] = df['GiaDieuChinh']
    df.loc[df['GiaDongCua'] == 0, 'GiaDongCua'] = 1
    df['adjustment_ratio'] = df['GiaDieuChinh'] / df['GiaDongCua']
    df['open_adj'] = df['GiaMoCua'] * df['adjustment_ratio']
    df['high_adj'] = df['GiaCaoNhat'] * df['adjustment_ratio']
    df['low_adj'] = df['GiaThapNhat'] * df['adjustment_ratio']
    df = df.rename(columns={'Ngay': 'time', 'open_adj': 'open', 'high_adj': 'high',
                            'low_adj': 'low', 'GiaDieuChinh': 'close', 
                            'KhoiLuongKhopLenh': 'volume', 'Ticker': 'ticker'})
    df['time'] = pd.to_datetime(df['time'], format="%d/%m/%Y")
    return df[['time', 'open', 'high', 'low', 'close', 'volume', 'ticker']].sort_values('time').reset_index(drop=True)

# --- Tá»« Step3.py (Ã” 3) ---
def get_stock_data(tickers: list, start_date: str, end_date: str) -> pd.DataFrame:
    st.info(f"Báº¯t Ä‘áº§u láº¥y dá»¯ liá»‡u cho {len(tickers)} mÃ£ (Äa luá»“ng - ThÃ¢n thiá»‡n)...")
    all_data = []
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    
    def fetch_one_ticker_isolated(ticker):
        time.sleep(0.2) 
        df_ticker = get_price_history_api(ticker, start_dt, end_dt) 
        if df_ticker is not None and not df_ticker.empty:
            return ticker, df_ticker
        else:
            return ticker, None

    progress_text = st.empty()
    progress_bar = st.progress(0)
    total_tickers = len(tickers)
    completed_count = 0

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(fetch_one_ticker_isolated, ticker): ticker for ticker in tickers}
        for future in as_completed(futures):
            ticker, df_ticker = future.result()
            completed_count += 1
            progress_bar.progress(completed_count / total_tickers)
            progress_text.text(f"Äang xá»­ lÃ½ mÃ£ {completed_count}/{total_tickers}: {ticker}...")
            
            if df_ticker is not None:
                all_data.append(df_ticker)
            else:
                st.warning(f"(!) KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho mÃ£: {ticker}")
    
    progress_text.empty()
    progress_bar.empty()

    if not all_data:
        st.error("(!) KhÃ´ng láº¥y Ä‘Æ°á»£c báº¥t ká»³ dá»¯ liá»‡u nÃ o.")
        return pd.DataFrame()

    final_df = pd.concat(all_data, ignore_index=True)
    final_df = final_df.sort_values(by=['ticker', 'time']).reset_index(drop=True)
    st.success("âœ… Láº¥y dá»¯ liá»‡u (Äa luá»“ng) thÃ nh cÃ´ng!")
    return final_df

# --- HÃ m tá»•ng há»£p tá»« Step5.py (Ã” 4) ---
def load_data(tickers_list, start_time_str, end_time_str, force_refresh):
    CACHE_FILE = 'vn30_data_cache.parquet'
    
    if os.path.exists(CACHE_FILE) and not force_refresh:
        st.info(f"--- Äang táº£i dá»¯ liá»‡u tá»« Cache ({CACHE_FILE}) ---")
        try:
            raw_data = pd.read_parquet(CACHE_FILE)
            st.success("âœ… Táº£i tá»« Cache thÃ nh cÃ´ng!")
            return raw_data
        except Exception as e:
            st.warning(f"Lá»—i Ä‘á»c file cache: {e}. Sáº½ táº£i láº¡i tá»« API.")

    if force_refresh:
        st.warning("--- Báº¯t buá»™c lÃ m má»›i (Force Refresh) ---")
    else:
        st.info("--- Láº§n cháº¡y Ä‘áº§u tiÃªn (Cache not found) ---")

    raw_data = get_stock_data(tickers_list, start_time_str, end_time_str)

    if not raw_data.empty:
        try:
            st.info(f"--- Äang lÆ°u vÃ o Cache ({CACHE_FILE}) ---")
            raw_data.to_parquet(CACHE_FILE)
            st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ táº£i vÃ  lÆ°u vÃ o Cache.")
        except Exception as e:
            st.error(f"Lá»–I khi lÆ°u Cache: {e}. Vui lÃ²ng cÃ i Ä‘áº·t 'pip install pyarrow'")
    
    return raw_data

# --- Tá»« Step7.py (Ã” 6) ---
def calculate_stats(returns_df: pd.DataFrame, he_so_scale: int) -> tuple:
    expected_returns = returns_df.mean() * he_so_scale
    cov_matrix = returns_df.cov() * he_so_scale
    return expected_returns, cov_matrix

# --- Tá»« Step11.py (Ã” 10) ---
def get_portfolio_stats(weights: np.array, 
                        expected_returns: pd.Series, 
                        cov_matrix: pd.DataFrame, 
                        risk_free_rate: float) -> tuple:
    port_return = np.sum(weights * expected_returns)
    port_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    port_sharpe = (port_return - risk_free_rate) / (port_risk + 1e-9) 
    return (port_return, port_risk, port_sharpe)

def minimize_negative_sharpe(weights: np.array, 
                             expected_returns: pd.Series, 
                             cov_matrix: pd.DataFrame,
                             risk_free_rate: float) -> float:
    return -get_portfolio_stats(weights, expected_returns, cov_matrix, risk_free_rate)[2]

def minimize_portfolio_risk(weights: np.array, 
                            expected_returns: pd.Series, 
                            cov_matrix: pd.DataFrame,
                            risk_free_rate: float) -> float:
    return get_portfolio_stats(weights, expected_returns, cov_matrix, risk_free_rate)[1]

# --- [Má»šI] HÃ m tÃ­nh Ä‘Æ°á»ng biÃªn hiá»‡u quáº£ lÃ½ thuyáº¿t ---
def calculate_theoretical_efficient_frontier(mean_returns, cov_matrix, risk_free_rate, num_points=100):
    num_assets = len(mean_returns)
    args = (mean_returns, cov_matrix, risk_free_rate)
    bounds = tuple((0.0, 1.0) for _ in range(num_assets))
    init_guess = num_assets * [1. / num_assets,]

    constraints_min_vol = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    opt_min_vol = minimize(minimize_portfolio_risk, init_guess, args=args,
                           method='SLSQP', bounds=bounds, constraints=constraints_min_vol)
    
    min_ret_global = np.sum(mean_returns * opt_min_vol.x)
    max_ret_global = mean_returns.max() 

    target_returns = np.linspace(min_ret_global, max_ret_global, num_points)
    efficient_risks = []
    real_returns = []

    for target in target_returns:
        constraints = (
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}, 
            {'type': 'eq', 'fun': lambda x: np.sum(mean_returns * x) - target}
        )
        opt = minimize(minimize_portfolio_risk, init_guess, args=args,
                       method='SLSQP', bounds=bounds, constraints=constraints)
        if opt.success:
            efficient_risks.append(opt.fun)
            real_returns.append(target)
            
    return pd.DataFrame({'Risk': efficient_risks, 'Return': real_returns})

# --- Tá»« Step10.py (Ã” 8) ---
def run_monte_carlo_sim(n_sims: int, 
                        expected_returns: pd.Series, 
                        cov_matrix: pd.DataFrame, 
                        risk_free_rate: float) -> pd.DataFrame:
    # [FIX] Cá»‘ Ä‘á»‹nh Seed Ä‘á»ƒ káº¿t quáº£ khÃ´ng bá»‹ nháº£y lung tung má»—i láº§n cháº¡y
    np.random.seed(42) 
    
    num_assets = len(expected_returns)
    results = np.zeros((3, n_sims))
    weights_record = []
    
    for i in range(n_sims):
        weights = np.random.random(num_assets)
        weights /= np.sum(weights)
        weights_record.append(weights)
        
        port_return, port_risk, port_sharpe = get_portfolio_stats(
            weights, expected_returns, cov_matrix, risk_free_rate
        )
        
        results[0, i] = port_return
        results[1, i] = port_risk
        results[2, i] = port_sharpe

    results_df = pd.DataFrame(results.T, columns=['Return', 'Risk', 'Sharpe'])
    weights_df = pd.DataFrame(weights_record, columns=expected_returns.index)
    sim_data_df = pd.concat([results_df, weights_df], axis=1)
    
    return sim_data_df

# --- Tá»« Step16.py (Ã” 13) ---
def run_simple_backtest(daily_returns_df: pd.DataFrame, 
                        portfolio_weights: np.array) -> tuple:
    port_returns_daily = daily_returns_df.dot(portfolio_weights)
    port_returns_daily = pd.Series(port_returns_daily, index=daily_returns_df.index)
    cumulative_returns = (1 + port_returns_daily).cumprod()
    return port_returns_daily, cumulative_returns


# === GIAO DIá»†N STREAMLIT ===

# --- Sidebar (Thanh bÃªn) ---
st.sidebar.header("Cáº¥u hÃ¬nh PhÃ¢n tÃ­ch")

start_date_input = st.sidebar.date_input(
    'Tá»« ngÃ y', value=datetime(2018, 1, 1)
)
end_date_input = st.sidebar.date_input(
    'Äáº¿n ngÃ y', value=datetime.now()
)

holding_period_tuple = st.sidebar.selectbox(
    'Thá»i háº¡n (Scale):',
    options=[('1 nÄƒm', 252), ('6 thÃ¡ng', 126), ('2 nÄƒm', 504), ('3 thÃ¡ng', 63)],
    format_func=lambda x: x[0]
)
HE_SO_SCALE = holding_period_tuple[1]

risk_free_rate_pct = st.sidebar.number_input(
    'LS Phi rá»§i ro (%):', value=4.0, step=0.1
)
RISK_FREE_RATE = risk_free_rate_pct / 100.0

N_SIMULATIONS = st.sidebar.number_input(
    'Sá»‘ láº§n MÃ´ phá»ng Monte Carlo:',
    min_value=1000, max_value=50000, value=5000, step=1000
)

force_refresh_checkbox = st.sidebar.checkbox(
    'LÃ m má»›i Dá»¯ liá»‡u (Bá» qua Cache & gá»i láº¡i API)'
)

run_button = st.sidebar.button("Báº®T Äáº¦U PHÃ‚N TÃCH", type="primary", use_container_width=True)

tickers_list = [
    'ACB', 'BCM', 'BID', 'BVH', 'CTG', 'FPT', 'GAS', 'GVR', 'HDB', 'HPG', 
    'LPB', 'MBB', 'MSN', 'MWG', 'PLX', 'SAB', 'SHB', 'SSB', 'SSI', 'STB', 
    'TCB', 'TPB', 'VCB', 'VHM', 'VIB', 'VIC', 'VJC', 'VNM', 'VPB', 'VRE'
]

# === QUY TRÃŒNH CHÃNH ===

if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False

if run_button:
    st.session_state.analysis_done = False 
    
    # 1. Táº£i Dá»¯ liá»‡u
    with st.spinner("â³ (1/7) Äang táº£i dá»¯ liá»‡u thÃ´..."):
        start_time_str = start_date_input.strftime('%Y-%m-%d')
        end_time_str = end_date_input.strftime('%Y-%m-%d')
        
        raw_data = load_data(tickers_list, start_time_str, end_time_str, force_refresh_checkbox)
        
        if raw_data.empty:
            st.error("KhÃ´ng táº£i Ä‘Æ°á»£c dá»¯ liá»‡u. Vui lÃ²ng thá»­ láº¡i.")
            st.stop()
        
        st.session_state.raw_data = raw_data
        st.session_state.start_time_str = start_time_str
    
    # 2. TÃ­nh Tá»· suáº¥t sinh lá»i
    with st.spinner("â³ (2/7) Äang tÃ­nh Tá»· suáº¥t sinh lá»i..."):
        raw_data.drop_duplicates(subset=['time', 'ticker'], keep='last', inplace=True)
        price_pivot = raw_data.pivot(index='time', columns='ticker', values='close')
        returns_df_raw = price_pivot.pct_change()
        returns_df = returns_df_raw.iloc[1:].dropna(how='all') 
        
        st.session_state.returns_df = returns_df
        st.session_state.price_pivot = price_pivot
    
    # 3. TÃ­nh Stats
    with st.spinner("â³ (3/7) Äang tÃ­nh Lá»£i nhuáº­n Ká»³ vá»ng & Hiá»‡p phÆ°Æ¡ng sai..."):
        expected_returns, cov_matrix = calculate_stats(returns_df, HE_SO_SCALE)
        
        valid_assets = expected_returns.dropna().index
        expected_returns = expected_returns[valid_assets]
        cov_matrix = cov_matrix.loc[valid_assets, valid_assets]
        
        st.session_state.expected_returns = expected_returns
        st.session_state.cov_matrix = cov_matrix
        st.session_state.returns_df = returns_df[valid_assets] 
        st.session_state.price_pivot = price_pivot[valid_assets]
    
    # 4. Cháº¡y Monte Carlo VÃ€ Efficient Frontier
    with st.spinner(f"â³ (4/7) Äang cháº¡y Monte Carlo & Dá»±ng Ä‘Æ°á»ng biÃªn hiá»‡u quáº£..."):
        sim_data_df = run_monte_carlo_sim(
            N_SIMULATIONS, 
            st.session_state.expected_returns, 
            st.session_state.cov_matrix, 
            RISK_FREE_RATE
        )
        st.session_state.sim_data_df = sim_data_df

        eff_frontier_df = calculate_theoretical_efficient_frontier(
            st.session_state.expected_returns, 
            st.session_state.cov_matrix, 
            RISK_FREE_RATE
        )
        st.session_state.eff_frontier_df = eff_frontier_df

    # 5. Cháº¡y Tá»‘i Æ°u hÃ³a
    with st.spinner("â³ (5/7) Äang cháº¡y Tá»‘i Æ°u hÃ³a..."):
        num_assets = len(st.session_state.expected_returns)
        args = (st.session_state.expected_returns, st.session_state.cov_matrix, RISK_FREE_RATE)
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0.0, 1.0) for _ in range(num_assets))

        # 1. Min Risk
        min_vol_guess_weights = sim_data_df.loc[sim_data_df['Risk'].idxmin()].values[3:3+num_assets]
        opt_min_vol = minimize(minimize_portfolio_risk, min_vol_guess_weights, args=args,
                               method='SLSQP', bounds=bounds, constraints=constraints)
        min_vol_weights = opt_min_vol.x

        # 2. Max Sharpe
        max_sharpe_guess_weights = sim_data_df.loc[sim_data_df['Sharpe'].idxmax()].values[3:3+num_assets]
        opt_max_sharpe = minimize(minimize_negative_sharpe, max_sharpe_guess_weights, args=args,
                                  method='SLSQP', bounds=bounds, constraints=constraints)
        max_sharpe_weights = opt_max_sharpe.x
        
        # 3. Max Return
        max_ret_weights = np.zeros(num_assets)
        max_ret_index = st.session_state.expected_returns.argmax()
        max_ret_weights[max_ret_index] = 1.0

        st.session_state.optimal_weights_df = pd.DataFrame({
            'Báº£o thá»§ (Min Risk)': min_vol_weights,
            'CÃ¢n báº±ng (Max Sharpe)': max_sharpe_weights,
            'Máº¡o hiá»ƒm (Max Return)': max_ret_weights
        }, index=st.session_state.expected_returns.index)
        
        st.session_state.optimal_weights_df.index.name = 'ticker'

        st.session_state.optimal_stats_dict = {
            'min_vol': get_portfolio_stats(min_vol_weights, *args),
            'max_sharpe': get_portfolio_stats(max_sharpe_weights, *args),
            'max_ret': get_portfolio_stats(max_ret_weights, *args)
        }

    # 6. Cháº¡y Backtest
    with st.spinner("â³ (6/7) Äang cháº¡y Backtest..."):
        returns_min_vol, cum_min_vol = run_simple_backtest(st.session_state.returns_df, min_vol_weights)
        returns_max_sharpe, cum_max_sharpe = run_simple_backtest(st.session_state.returns_df, max_sharpe_weights)
        returns_max_ret, cum_max_ret = run_simple_backtest(st.session_state.returns_df, max_ret_weights)
        
        st.session_state.all_cumulative_df = pd.DataFrame({
            'Báº£o thá»§ (Min Risk)': cum_min_vol,
            'CÃ¢n báº±ng (Max Sharpe)': cum_max_sharpe,
            'Máº¡o hiá»ƒm (Max Return)': cum_max_ret
        }).dropna()
        
        st.session_state.all_returns_df = pd.DataFrame({
            'Báº£o thá»§ (Min Risk)': returns_min_vol,
            'CÃ¢n báº±ng (Max Sharpe)': returns_max_sharpe,
            'Máº¡o hiá»ƒm (Max Return)': returns_max_ret
        }).dropna()

    # 7. TÃ­nh Metrics
    with st.spinner("â³ (7/7) Äang tÃ­nh toÃ¡n Metrics hiá»‡u suáº¥t..."):
        metrics = ['Tá»•ng Lá»£i nhuáº­n (Cumulative)', 'Lá»£i nhuáº­n TB NÄƒm (Annualized)', 
                   'Rá»§i ro NÄƒm (Annualized)', 'Má»©c sá»¥t giáº£m Tá»‘i Ä‘a (Max Drawdown)', 
                   'Chá»‰ sá»‘ Sharpe (Historical)']
        summary_table = pd.DataFrame(index=metrics)
        
        for port_name in st.session_state.all_returns_df.columns:
            returns_series = st.session_state.all_returns_df[port_name]
            summary_table.loc['Tá»•ng Lá»£i nhuáº­n (Cumulative)', port_name] = qs.stats.comp(returns_series)
            summary_table.loc['Lá»£i nhuáº­n TB NÄƒm (Annualized)', port_name] = qs.stats.cagr(returns_series)
            summary_table.loc['Rá»§i ro NÄƒm (Annualized)', port_name] = qs.stats.volatility(returns_series)
            summary_table.loc['Má»©c sá»¥t giáº£m Tá»‘i Ä‘a (Max Drawdown)', port_name] = qs.stats.max_drawdown(returns_series)
            summary_table.loc['Chá»‰ sá»‘ Sharpe (Historical)', port_name] = qs.stats.sharpe(returns_series, rf=RISK_FREE_RATE)
        
        st.session_state.summary_table = summary_table
    
    st.session_state.analysis_done = True
    st.success("ğŸ‰ PhÃ¢n tÃ­ch hoÃ n táº¥t! Xem káº¿t quáº£ bÃªn dÆ°á»›i.")

# === HIá»‚N THá»Š Káº¾T QUáº¢ ===

if st.session_state.analysis_done:
    
    tab1, tab2, tab3 = st.tabs(["ÄÆ°á»ng biÃªn Hiá»‡u quáº£ & Tá»· trá»ng", "Káº¿t quáº£ Backtest", "Dá»¯ liá»‡u ThÃ´ & TÆ°Æ¡ng quan"])

    with tab1:
        st.header("1. PhÃ¢n bá»• Tá»· trá»ng & ÄÆ°á»ng biÃªn Hiá»‡u quáº£")
        
        # --- PHáº¦N 1: Báº¢NG Sá» LIá»†U ---
        st.subheader("PhÃ¢n bá»• Tá»· trá»ng Tá»‘i Æ°u")
        df_weights = st.session_state.optimal_weights_df
        df_weights_styled = df_weights[(df_weights > 0.001).any(axis=1)].style.format("{:.2%}")
        st.dataframe(df_weights_styled, use_container_width=True)
        
        st.divider()
        
        # --- PHáº¦N 2: BIá»‚U Äá»’ Tá»¶ TRá»ŒNG ---
        st.subheader("Biá»ƒu Ä‘á»“ Tá»· trá»ng")
        df_plot = df_weights[(df_weights > 0.001).any(axis=1)].copy()
        
        df_plot_long = df_plot.reset_index().melt(
            id_vars='ticker', 
            var_name='Danh má»¥c', 
            value_name='Tá»· trá»ng'
        )
        df_plot_long.rename(columns={'ticker': 'MÃ£ CP'}, inplace=True)
        
        fig_bars = px.bar(
            df_plot_long, x='Danh má»¥c', y='Tá»· trá»ng', color='MÃ£ CP',
            text_auto='.2%',
            title='PhÃ¢n bá»• Tá»· trá»ng Tá»‘i Æ°u theo 3 Kháº©u vá»‹ Rá»§i ro'
        )
        fig_bars.update_layout(template='plotly_dark', yaxis_tickformat='.0%', height=500)
        st.plotly_chart(fig_bars, use_container_width=True)
            
        st.divider()

        # --- PHáº¦N 3: BIá»‚U Äá»’ ÄÆ¯á»œNG BIÃŠN HIá»†U QUáº¢ ---
        st.subheader("ÄÆ°á»ng biÃªn Hiá»‡u quáº£ ToÃ n diá»‡n (cÃ³ CAL)")
        
        # FIX: THÃŠM render_mode='svg' Äá»‚ Sá»¬A Lá»–I WEBGL
        sim_data_df = st.session_state.sim_data_df
        fig = px.scatter(
            sim_data_df, x='Risk', y='Return', color='Sharpe',
            color_continuous_scale='Viridis',
            hover_data={col: ':.2%' for col in sim_data_df.columns if col not in ['Risk', 'Return', 'Sharpe']} | {'Risk': ':.2%','Return': ':.2%','Sharpe': ':.2f'},
            title=f'ÄÆ°á»ng biÃªn Hiá»‡u quáº£ - {N_SIMULATIONS} danh má»¥c (Rf={RISK_FREE_RATE:.1%})',
            render_mode='svg' # <--- ÄÃ‚Y LÃ€ FIX QUAN TRá»ŒNG
        )
        
        # Váº½ Ä‘Æ°á»ng lÃ½ thuyáº¿t
        eff_df = st.session_state.eff_frontier_df
        fig.add_trace(go.Scatter(
            x=eff_df['Risk'], y=eff_df['Return'], mode='lines', 
            line=dict(color='white', width=3, dash='dash'),
            name='ÄÆ°á»ng biÃªn Hiá»‡u quáº£ (LÃ½ thuyáº¿t)'
        ))
        
        # Váº½ cÃ¡c Ä‘iá»ƒm tá»‘i Æ°u
        stats_dict = st.session_state.optimal_stats_dict
        stats_min_vol = stats_dict['min_vol']
        stats_max_sharpe = stats_dict['max_sharpe']
        stats_max_ret = stats_dict['max_ret']
        
        fig.add_trace(go.Scatter(x=[stats_min_vol[1]], y=[stats_min_vol[0]], mode='markers', marker=dict(color='white', size=15, symbol='star', line=dict(color='black', width=2)), name='Báº£o thá»§ (Min Risk)'))
        fig.add_trace(go.Scatter(x=[stats_max_sharpe[1]], y=[stats_max_sharpe[0]], mode='markers', marker=dict(color='cyan', size=15, symbol='star', line=dict(color='black', width=2)), name='CÃ¢n báº±ng (Max Sharpe)'))
        fig.add_trace(go.Scatter(x=[stats_max_ret[1]], y=[stats_max_ret[0]], mode='markers', marker=dict(color='red', size=15, symbol='star', line=dict(color='black', width=2)), name='Máº¡o hiá»ƒm (Max Return)'))
        
        # Váº½ ÄÆ°á»ng CAL
        sharpe_risk = stats_max_sharpe[1]
        sharpe_return = stats_max_sharpe[0]
        x_cal = [0, sharpe_risk * 1.5] 
        y_cal = [RISK_FREE_RATE, (sharpe_return - RISK_FREE_RATE) / (sharpe_risk + 1e-9) * (sharpe_risk * 1.5) + RISK_FREE_RATE]
        fig.add_trace(go.Scatter(x=x_cal, y=y_cal, mode='lines', line=dict(color='lime', width=2, dash='dash'), name='ÄÆ°á»ng PhÃ¢n bá»• Vá»‘n (CAL)'))

        fig.update_layout(
            height=800,
            xaxis_tickformat='.1%', yaxis_tickformat='.1%',
            legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5),
            margin=dict(b=100)
        )
        st.plotly_chart(fig, use_container_width=True)

    with tab2:
        st.header("2. Káº¿t quáº£ Backtest")
        
        st.subheader("Báº£ng Tá»•ng káº¿t Chá»‰ sá»‘ Hiá»‡u suáº¥t")
        summary_table = st.session_state.summary_table
        percent_rows = summary_table.index.difference(['Chá»‰ sá»‘ Sharpe (Historical)'])
        number_row = pd.Index(['Chá»‰ sá»‘ Sharpe (Historical)'])
        styler = summary_table.style
        styler.format('{:,.2%}', subset=(percent_rows, slice(None)))
        styler.format('{:,.2f}', subset=(number_row, slice(None)))
        st.dataframe(styler, use_container_width=True)
        
        st.subheader(f"So sÃ¡nh Hiá»‡u quáº£ TÄƒng trÆ°á»Ÿng (Tá»« {st.session_state.start_time_str})")
        fig_backtest = px.line(
            st.session_state.all_cumulative_df, 
            title=f'So sÃ¡nh Hiá»‡u quáº£ TÄƒng trÆ°á»Ÿng (Tá»« {st.session_state.start_time_str})'
        )
        fig_backtest.update_layout(
            template='plotly_dark', 
            yaxis_title='GiÃ¡ trá»‹ Danh má»¥c (Báº¯t Ä‘áº§u tá»« 1.0)', 
            legend_title='Danh má»¥c',
            yaxis_tickformat='.2f'
        )
        st.plotly_chart(fig_backtest, use_container_width=True)
        
        st.subheader("PhÃ¢n tÃ­ch Chi tiáº¿t Hiá»‡u suáº¥t Backtest")
        port_names = summary_table.columns
        fig_metrics = make_subplots(
            rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.1,
            subplot_titles=("So sÃ¡nh Lá»£i nhuáº­n", "So sÃ¡nh Rá»§i ro", "So sÃ¡nh Tá»· lá»‡ (Sharpe)")
        )
        # 1. Lá»£i nhuáº­n
        return_metrics = ['Tá»•ng Lá»£i nhuáº­n (Cumulative)', 'Lá»£i nhuáº­n TB NÄƒm (Annualized)']
        for metric in return_metrics:
            fig_metrics.add_trace(go.Bar(
                x=port_names, y=summary_table.loc[metric], text=summary_table.loc[metric],
                texttemplate='%{y:.2%}', name=metric
            ), row=1, col=1)
        # 2. Rá»§i ro
        risk_metrics = ['Rá»§i ro NÄƒm (Annualized)', 'Má»©c sá»¥t giáº£m Tá»‘i Ä‘a (Max Drawdown)']
        for metric in risk_metrics:
            fig_metrics.add_trace(go.Bar(
                x=port_names, y=summary_table.loc[metric], text=summary_table.loc[metric],
                texttemplate='%{y:.2%}', name=metric
            ), row=2, col=1)
        # 3. Sharpe
        sharpe_metric = 'Chá»‰ sá»‘ Sharpe (Historical)'
        fig_metrics.add_trace(go.Bar(
            x=port_names, y=summary_table.loc[sharpe_metric], text=summary_table.loc[sharpe_metric],
            texttemplate='%{y:.2f}', name=sharpe_metric
        ), row=3, col=1)
        
        fig_metrics.update_layout(height=1000, template='plotly_dark', barmode='group')
        fig_metrics.update_yaxes(title_text='Lá»£i nhuáº­n', tickformat='.0%', row=1, col=1)
        fig_metrics.update_yaxes(title_text='Rá»§i ro', tickformat='.0%', row=2, col=1)
        fig_metrics.update_yaxes(title_text='Tá»· lá»‡', tickformat='.2f', row=3, col=1)
        st.plotly_chart(fig_metrics, use_container_width=True)
        
    with tab3:
        st.header("3. Dá»¯ liá»‡u ThÃ´ & PhÃ¢n tÃ­ch TÆ°Æ¡ng quan")
        
        st.subheader("Heatmap Ma tráº­n TÆ°Æ¡ng quan")
        returns_df = st.session_state.returns_df
        correlation_matrix = returns_df.corr()
        labels = correlation_matrix.columns
        fig_heatmap = go.Figure(data=go.Heatmap(
            z=correlation_matrix.values, x=labels, y=labels,
            colorscale='RdBu_r', zmin=-1, zmax=1,
            hoverongaps=False
        ))
        fig_heatmap.update_layout(
            title='Heatmap Ma tráº­n TÆ°Æ¡ng quan (VN30)', template='plotly_dark',
            height=700, width=800,
            yaxis_autorange='reversed'
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        st.subheader("Dá»¯ liá»‡u GiÃ¡ ÄÃ³ng cá»­a (Pivot)")
        st.dataframe(st.session_state.price_pivot.tail())
        
        st.subheader("Dá»¯ liá»‡u Tá»· suáº¥t sinh lá»i (HÃ ng ngÃ y)")
        st.dataframe(st.session_state.returns_df.tail())
        
        st.subheader("Dá»¯ liá»‡u ThÃ´ (Táº£i vá»)")
        st.dataframe(st.session_state.raw_data.tail())